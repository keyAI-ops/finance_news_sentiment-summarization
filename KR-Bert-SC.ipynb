{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vy4rHbFxHXOv"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":25272,"status":"ok","timestamp":1677166799106,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"ZVbvK-97HVdn"},"outputs":[],"source":["import logging\n","import math\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","from datasets import load_dataset\n","\n","import transformers\n","from transformers import (\n","    CONFIG_MAPPING,\n","    MODEL_FOR_MASKED_LM_MAPPING,\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorForLanguageModeling,\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n",")\n","from transformers.trainer_utils import get_last_checkpoint, is_main_process"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4516,"status":"ok","timestamp":1677166803612,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"CqiN6cQvIG6y"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-FinBert-SC\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert-SC\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["db0c78052d8d464a99a34698dcd689a3","0715fb3a768c44d2b086876f9abb7f81","8e9366ee963540c994bea810de2cef22","3194f036707f4a118d3e2e722d74d979","68bbe664024143e38b367fd4add0985d","e331b095961d4ff99083fe75c64f46c8","436f504e5dea48fa9ac9fe29375bd260","541419a7c07c4fff83c7084da9b89f68","28c6947e585c4e528da25179ea2d0961","f41d44e1930346dcb441e57e0d2af16c","a036cbd52c534d2a93a5bc1b09d683ae"]},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677166803613,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"UKn_RVDiYai4","outputId":"b89d3ea2-6dca-44c8-d45f-d9fe664096bb"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-139b2c4b48e6851f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db0c78052d8d464a99a34698dcd689a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["INPUT_FILE = '/content/drive/MyDrive/Project3/2.Preprocess/out/0.7data_for_transformer.csv' #change\n","\n","datasets = load_dataset('csv', data_files=INPUT_FILE)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677166803613,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"kpgPDcqjMKok","outputId":"df018d09-b531-4632-f824-5fc4da7fef6d"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-139b2c4b48e6851f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-139b2c4b48e6851f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]}],"source":["# split data - train, validation\n","datasets[\"validation\"] = load_dataset(\n","                'csv', \n","                data_files=INPUT_FILE,\n","                split='train[:30%]',\n","            )\n","datasets[\"train\"] = load_dataset(\n","                'csv', \n","                data_files=INPUT_FILE,\n","                split=\"train[30%:]\",\n","            )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677166803613,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"HaL-TlzeNfWx"},"outputs":[],"source":["column_names = datasets[\"train\"].column_names\n","text_column_name = \"text\" if \"text\" in column_names else column_names[0]"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677166803614,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"QS0GYtqiNfht"},"outputs":[],"source":["max_seq_length = min(512, tokenizer.model_max_length)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1677166804120,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"Z1FQOMHONfkU","outputId":"4950f8b6-a2d4-4129-b92d-1f7fd2b316b8"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-139b2c4b48e6851f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-9c96bac35870935b.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-139b2c4b48e6851f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-40933d77d2c48c60.arrow\n"]}],"source":["## When using line_by_line, we just tokenize each nonempty line.\n","\n","padding = \"max_length\" # \"max_length\" if data_args.pad_to_max_length else False\n","\n","def tokenize_function(examples):\n","            # Remove empty lines\n","            examples[\"text\"] = [line for line in examples[\"text\"] if len(line) > 0 and not line.isspace()]\n","            return tokenizer(\n","                examples[\"text\"],\n","                padding=padding,\n","                truncation=True,\n","                max_length=max_seq_length,\n","                # We use this option because DataCollatorForLanguageModeling (see below) is more efficient when it\n","                # receives the `special_tokens_mask`.\n","                return_special_tokens_mask=True,\n","            )\n","\n","tokenized_datasets = datasets.map(\n","            tokenize_function,\n","            batched=True,\n","            #num_proc=data_args.preprocessing_num_workers,\n","            remove_columns=[text_column_name],   # ?\n","            #load_from_cache_file=not data_args.overwrite_cache,\n","        )"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677166804120,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"JyJjwu6oNfm8"},"outputs":[],"source":["# Tokenizing\n","train_dataset = tokenized_datasets[\"train\"]\n","eval_dataset = tokenized_datasets[\"validation\"]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1677166804120,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"dh1onYJbtr0o","outputId":"1e90f2df-753c-4c2b-fecc-64a8fb34150b"},"outputs":[{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7f91e1f033a0>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from torch.utils.data import DataLoader\n","\n","dataloader_train = DataLoader(train_dataset, batch_size=4)\n","dataloader_train"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677166804121,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"N9iVJLlivZIn"},"outputs":[],"source":["# train_features, train_labels = next(iter(dataloader_train))\n","# print(f\"Feature batch shape: {train_features.size()}\")\n","# print(f\"Labels batch shape: {train_labels.size()}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677166804121,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"ALKX3kp_IeQK"},"outputs":[],"source":["# Data collator\n","# This one will take care of randomly masking the tokens.\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677166804121,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"wnG9hqr6kKEb","outputId":"16a7f3ae-f4ed-4469-d185-4858818be63d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}],"source":["OUTPUT_PATH = '/content/drive/MyDrive/Project3/3.Classification' # change\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_PATH+'/out',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=8,   # batch size per device during training\n","    per_device_eval_batch_size=8,   # batch size for evaluation\n","    warmup_steps=0,               # number of warmup steps for learning rate scheduler\n","    weight_decay=0.0,               # strength of weight decay\n","    logging_dir='/logs',            # directory for storing logs\n","    logging_steps=500,               # How often to print logs\n","    do_train=True,                   # Perform training\n","    do_eval=True,                    # Perform evaluation\n","    evaluation_strategy=\"epoch\",     # evalute after eachh epoch\n","    gradient_accumulation_steps=1,  # total number of steps before back propagation\n","    #fp16=True,                       # Use mixed precision\n","    #fp16_opt_level=\"01\",             # mixed precision mode\n","    run_name=\"First trial\",       # experiment name\n","    seed=42                           # Seed for experiment reproducibility 3x3\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677166804121,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"fZMgK_ETIDtS"},"outputs":[],"source":["# Initialize our Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":685},"executionInfo":{"elapsed":151824,"status":"error","timestamp":1677166955940,"user":{"displayName":"Hye yoon Kim","userId":"18155519174760077312"},"user_tz":-540},"id":"gQ6X_SlIHac_","outputId":"602af158-77df-427b-dda6-d2d4c3048699"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: special_tokens_mask. If special_tokens_mask are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 589\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 222\n","  Number of trainable parameters = 101403651\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  2/222 : < :, Epoch 0.01/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-afebbb316b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_last_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Project3/3.Classification/out/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Saves the tokenizer too for easy upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2555\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["## train\n","last_checkpoint = get_last_checkpoint('/content/drive/MyDrive/Project3/3.Classification/out/')\n","train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\n","trainer.save_model()  # Saves the tokenizer too for easy upload\n","metrics = train_result.metrics\n","\n","# max_train_samples = (\n","#     data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset\n","#     )\n","#     metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","#     trainer.log_metrics(\"train\", metrics)\n","#     trainer.save_metrics(\"train\", metrics)\n","#     trainer.save_state()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXO6q1cfH214"},"outputs":[],"source":["## eval\n","metrics = trainer.evaluate()\n","\n","max_val_samples = data_args.max_val_samples if data_args.max_val_samples is not None else len(eval_dataset)\n","metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n","perplexity = math.exp(metrics[\"eval_loss\"])\n","metrics[\"perplexity\"] = perplexity\n","\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMJMAAEJ8lqRsAZin0T2yhk","mount_file_id":"1iOcxjDQIxkphjeMaOTz5gQ7BCrQS2kTe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0715fb3a768c44d2b086876f9abb7f81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e331b095961d4ff99083fe75c64f46c8","placeholder":"​","style":"IPY_MODEL_436f504e5dea48fa9ac9fe29375bd260","value":"100%"}},"28c6947e585c4e528da25179ea2d0961":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3194f036707f4a118d3e2e722d74d979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f41d44e1930346dcb441e57e0d2af16c","placeholder":"​","style":"IPY_MODEL_a036cbd52c534d2a93a5bc1b09d683ae","value":" 1/1 [00:00&lt;00:00, 25.51it/s]"}},"436f504e5dea48fa9ac9fe29375bd260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"541419a7c07c4fff83c7084da9b89f68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68bbe664024143e38b367fd4add0985d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9366ee963540c994bea810de2cef22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_541419a7c07c4fff83c7084da9b89f68","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28c6947e585c4e528da25179ea2d0961","value":1}},"a036cbd52c534d2a93a5bc1b09d683ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db0c78052d8d464a99a34698dcd689a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0715fb3a768c44d2b086876f9abb7f81","IPY_MODEL_8e9366ee963540c994bea810de2cef22","IPY_MODEL_3194f036707f4a118d3e2e722d74d979"],"layout":"IPY_MODEL_68bbe664024143e38b367fd4add0985d"}},"e331b095961d4ff99083fe75c64f46c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f41d44e1930346dcb441e57e0d2af16c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
